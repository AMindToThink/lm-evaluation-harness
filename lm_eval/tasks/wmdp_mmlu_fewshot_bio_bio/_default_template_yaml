dataset_path: AMindToThink/mmlu_wmdp_bio_combined
test_split: wmdp_test
training_split: null
validation_split: mmlu_test # For AMindToThink's purposes, there's no reason not to use the test set because this is an adversarial setting and I want more adversarial examples to have a better estimate.
num_fewshot: null # Changed from 0 to null because AMindToThink wants to evaluate fewshot even though it will use test set because he cares about comparisons not absolute performance
output_type: multiple_choice
doc_to_text: "{{question.strip()}}\nA. {{choices[0]}}\nB. {{choices[1]}}\nC. {{choices[2]}}\nD. {{choices[3]}}\nAnswer:"
doc_to_choice: ["A", "B", "C", "D"]
doc_to_target: answer
metric_list:
  - metric: acc
    aggregation: mean
    higher_is_better: true
metadata:
  version: 1
